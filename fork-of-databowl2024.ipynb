{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60305,"databundleVersionId":6654553,"sourceType":"competition"},{"sourceId":7360429,"sourceType":"datasetVersion","datasetId":4275335}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy import stats\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom copy import deepcopy\n\ngames_csv_path = '/kaggle/input/nfl-big-data-bowl-2024/'\n\n# Load the additional required datasets\nplays_df = pd.read_csv(games_csv_path +'plays.csv')\nplayers_df = pd.read_csv(games_csv_path +'players.csv')\ngames_df = pd.read_csv(games_csv_path +'games.csv')\ntackles_df = pd.read_csv(games_csv_path +'tackles.csv')\n\ndef calculate_regression_stats(x_data, y_data):\n    \"\"\"\n    Calculate both the correlation coefficient and the R-squared value for a linear fit.\n    \n    Parameters:\n    x_data (iterable): The x-values of the data points.\n    y_data (iterable): The y-values of the data points.\n    \n    Returns:\n    tuple: A tuple containing the correlation coefficient and the R-squared value.\n    \"\"\"\n    slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n    r_squared = r_value ** 2\n    return r_value, r_squared\n\nteam_colors = {\n    'ARI': '#97233F',  # Arizona Cardinals\n    'ATL': '#A71930',  # Atlanta Falcons\n    'BAL': '#241773',  # Baltimore Ravens\n    'BUF': '#00338D',  # Buffalo Bills\n    'CAR': '#0085CA',  # Carolina Panthers\n    'CHI': '#C83803',  # Chicago Bears\n    'CIN': '#FB4F14',  # Cincinnati Bengals\n    'CLE': '#FF3C00',  # Cleveland Browns\n    'DAL': '#041E42',  # Dallas Cowboys\n    'DEN': '#FB4F14',  # Denver Broncos\n    'DET': '#0076B6',  # Detroit Lions\n    'GB':  '#203731',  # Green Bay Packers\n    'HOU': '#03202F',  # Houston Texans\n    'IND': '#002C5F',  # Indianapolis Colts\n    'JAX': '#006778',  # Jacksonville Jaguars\n    'KC':  '#E31837',  # Kansas City Chiefs\n    'LA':  '#003594',  # Los Angeles Rams\n    'LAC': '#0080C6',  # Los Angeles Chargers\n    'LV':  '#A5ACAF',  # Las Vegas Raiders\n    'MIA': '#008E97',  # Miami Dolphins\n    'MIN': '#4F2683',  # Minnesota Vikings\n    'NE':  '#002244',  # New England Patriots\n    'NO':  '#D3BC8D',  # New Orleans Saints\n    'NYG': '#0B2265',  # New York Giants\n    'NYJ': '#125740',  # New York Jets\n    'PHI': '#004C54',  # Philadelphia Eagles\n    'PIT': '#FFB612',  # Pittsburgh Steelers\n    'SEA': '#002244',  # Seattle Seahawks\n    'SF':  '#AA0000',  # San Francisco 49ers\n    'TB':  '#D50A0A',  # Tampa Bay Buccaneers\n    'TEN': '#0C2340',  # Tennessee Titans\n    'WAS': '#773141',  # Washington Commanders\n}\n\n# Calculating a score for each play based on tackles and assists\n# Base score is 0, each tackle is 1 point, each assist is 0.5 points\n# Total score for a play is capped at 1 point\n\n# Calculating individual player scores within each play\ntackles_df['player_score'] = tackles_df['tackle'] + 0.5 * tackles_df['assist']\n\n# Grouping by gameId and playId to calculate total score for each play\nplay_scores = tackles_df.groupby(['gameId', 'playId'])['player_score'].sum().reset_index()\nplay_scores['total_score'] = play_scores['player_score'].apply(lambda x: min(x, 1))\nplay_scores = play_scores.drop('player_score', axis=1)\n\nplay_scores_with_team = play_scores.merge(plays_df[['gameId', 'playId', 'defensiveTeam']], on=['gameId', 'playId'], how='left')\n\n# Grouping by defensiveTeam to calculate total points for each team\nteam_total_scores = play_scores_with_team.groupby('defensiveTeam')['total_score'].sum().reset_index()\nteam_total_scores.columns = ['Team', 'Total Tackle Play Score']\nteam_total_scores = team_total_scores.sort_values(by='Total Tackle Play Score', ascending=False)\n\nhome_games = games_df.groupby('homeTeamAbbr').size().rename('games')\nvisitor_games = games_df.groupby('visitorTeamAbbr').size().rename('games')\ntotal_games = home_games.add(visitor_games, fill_value=0)\n# Merging the total games count with the team total scores\nteam_scores_games = team_total_scores.merge(total_games, left_on='Team', right_index=True)\n\n# Calculating the average 'Tackle Play Score' per game for each team\nteam_scores_games['Average Tackle Play Score per Game'] = team_scores_games['Total Tackle Play Score'] / team_scores_games['games']\n\n# Counting wins for home and visiting teams\nhome_wins = games_df[games_df['homeFinalScore'] > games_df['visitorFinalScore']].groupby('homeTeamAbbr').size()\nvisitor_wins = games_df[games_df['visitorFinalScore'] > games_df['homeFinalScore']].groupby('visitorTeamAbbr').size()\n\ntotal_wins = home_wins.add(visitor_wins, fill_value=0).rename('Wins')\ngames_played = total_games\n\n# Creating a DataFrame with wins and games played\nteam_performance = pd.DataFrame({'Wins': total_wins, 'Games Played': games_played})\nteam_performance['Win Percentage'] = team_performance['Wins'] / team_performance['Games Played']\nteam_performance = team_performance.reset_index().rename(columns={'index': 'Team'})","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:30.096989Z","iopub.execute_input":"2024-01-08T06:19:30.097916Z","iopub.status.idle":"2024-01-08T06:19:30.476427Z","shell.execute_reply.started":"2024-01-08T06:19:30.097878Z","shell.execute_reply":"2024-01-08T06:19:30.475565Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Tackles in the NFL: An Analytical Approach\n\nWelcome to my analysis for the NFL Big Data Bowl 2024.\n\nIn this initial stage, I am focusing on two key aspects of the game: the win rates and the number of tackles per game, analyzed on a team-by-team basis. My objective is to develop an initial understanding of how these metrics correlate with team performance and strategies.\n\nThe driving force behind this exploration is to uncover patterns and insights that might explain the dynamics of success in the NFL. As I delve into the data, my goal is to unearth findings that not only enrich my understanding of the sport but also provide valuable insights for teams, strategists, and football enthusiasts.\n\nJoin me on this journey of data exploration in the captivating world of the NFL.\n","metadata":{}},{"cell_type":"markdown","source":"## Initial Analysis: High Win Rates and Tackle Influence\n\nLet's take a quick glance at the teams that boasted the highest win rates during the first half of the last NFL season. We'll also explore how the win rates correlate with their tackling statistics.","metadata":{}},{"cell_type":"code","source":"# Sorting the team_performance DataFrame by 'Win Percentage' in descending order to rank the teams\nranked_team_performance = team_performance.sort_values(by='Win Percentage', ascending=False)\nranked_team_performance = ranked_team_performance.reset_index(drop=True)\n\nranked_team_performance[['Team', 'Win Percentage']].head(10)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-01-08T06:19:31.490174Z","iopub.execute_input":"2024-01-08T06:19:31.491339Z","iopub.status.idle":"2024-01-08T06:19:31.513507Z","shell.execute_reply.started":"2024-01-08T06:19:31.491296Z","shell.execute_reply":"2024-01-08T06:19:31.512397Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data = team_performance.merge(team_scores_games[['Team', 'Average Tackle Play Score per Game']], on='Team')\nmerged_data['Team Color'] = merged_data['Team'].map(team_colors)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:31.514935Z","iopub.execute_input":"2024-01-08T06:19:31.515471Z","iopub.status.idle":"2024-01-08T06:19:31.52676Z","shell.execute_reply.started":"2024-01-08T06:19:31.515433Z","shell.execute_reply":"2024-01-08T06:19:31.525496Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 9))\n\nsns.regplot(x='Average Tackle Play Score per Game', y='Win Percentage', data=merged_data)\n\nfor team in merged_data['Team'].unique():\n    team_data = merged_data[merged_data['Team'] == team]\n    plt.scatter(team_data['Average Tackle Play Score per Game'], team_data['Win Percentage'], \n                color=team_data['Team Color'].iloc[0], label=team)\n\nfor _, row in merged_data.iterrows():\n    if row['Team'] in ['PHI', 'BUF', 'KC', 'MIN', 'NYG']:\n        plt.annotate(row['Team'], \n                     (row['Average Tackle Play Score per Game'], row['Win Percentage']),\n                     textcoords=\"offset points\", # Positioning label\n                     xytext=(15,-5),             # Distance from text to points (x,y)\n                     ha='center')              \n\nplt.xlabel('Average # of Tackle Plays per Game')\nplt.ylabel('Win Percentage')\nplt.title('Win Percentage vs Average Tackle Plays (with Linear Fit)')\nplt.legend(title='Teams', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:31.52824Z","iopub.execute_input":"2024-01-08T06:19:31.528814Z","iopub.status.idle":"2024-01-08T06:19:32.76846Z","shell.execute_reply.started":"2024-01-08T06:19:31.528777Z","shell.execute_reply":"2024-01-08T06:19:32.767721Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Two key observations:**\n\n1. **Lack of Strong Linear Correlation:** The data points do not show a strong linear correlation between win rates and the number of tackle plays. The distribution of points appears somewhat dispersed, indicating that the relationship between these two variables might not be straightforward.\n\n2. **Trend in the Linear Fit:** Despite the lack of a strong correlation, the linear fit suggests a general trend where the win rate tends to decline as the number of tackle plays increases. This trend aligns with the intuitive understanding that more tackles might indicate more defensive plays, which could correlate with lower win rates.","metadata":{}},{"cell_type":"markdown","source":"In addition to analyzing win rates, we will delve into the \"**Performance Index**,\" a metric that evaluates a team's scoring efficiency in each game. This index is calculated as the ratio of the team's score to the total points scored in the game, providing a nuanced view of how effectively a team capitalizes on its scoring opportunities. For a given team in a specific game, the Performance Index is computed as:\n\n$$\n\\text{Performance Index} = \\frac{\\text{Team's Score}}{\\text{Team's Score} + \\text{Opponent's Score}}\n$$\n\nThis index ranges from 0 to 1, where a higher value indicates a higher proportion of points scored by the team. It provides a normalized measure of how effectively a team converted opportunities into points, relative to the overall scoring in the game.\n","metadata":{}},{"cell_type":"code","source":"# Calculate the performance index for each game\ngames_df['homeTeamIndex'] = games_df['homeFinalScore'] / (games_df['homeFinalScore'] + games_df['visitorFinalScore'])\ngames_df['visitorTeamIndex'] = games_df['visitorFinalScore'] / (games_df['homeFinalScore'] + games_df['visitorFinalScore'])\ngames_df.fillna(0, inplace=True)\n\nhome_performance = games_df[['homeTeamAbbr', 'homeTeamIndex']].rename(columns={'homeTeamAbbr': 'Team', 'homeTeamIndex': 'PerformanceIndex'})\nvisitor_performance = games_df[['visitorTeamAbbr', 'visitorTeamIndex']].rename(columns={'visitorTeamAbbr': 'Team', 'visitorTeamIndex': 'PerformanceIndex'})\n\ncombined_performance = pd.concat([home_performance, visitor_performance])\naverage_performance_index = combined_performance.groupby('Team')['PerformanceIndex'].mean().sort_values(ascending=False)\n\n# Plotting\nplt.figure(figsize=(15, 8))\naverage_performance_index.plot(kind='bar')\nplt.xlabel('Team')\nplt.ylabel('Average Performance Index')\nplt.title('Average Performance Index for Each Team')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:32.7696Z","iopub.execute_input":"2024-01-08T06:19:32.770114Z","iopub.status.idle":"2024-01-08T06:19:33.253827Z","shell.execute_reply.started":"2024-01-08T06:19:32.770085Z","shell.execute_reply":"2024-01-08T06:19:33.252847Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_performance_df = average_performance_index.reset_index()\naverage_performance_df.columns = ['Team', 'Average Performance Index']\n\nmerged_data = merged_data.merge(average_performance_df, on='Team', how='left')","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:33.260329Z","iopub.execute_input":"2024-01-08T06:19:33.261291Z","iopub.status.idle":"2024-01-08T06:19:33.269572Z","shell.execute_reply.started":"2024-01-08T06:19:33.261256Z","shell.execute_reply":"2024-01-08T06:19:33.268632Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a quick look at how the Performance Index correlates with the tackling statistics.","metadata":{"execution":{"iopub.status.busy":"2024-01-06T01:31:23.979306Z","iopub.execute_input":"2024-01-06T01:31:23.980164Z","iopub.status.idle":"2024-01-06T01:31:24.010159Z","shell.execute_reply.started":"2024-01-06T01:31:23.980126Z","shell.execute_reply":"2024-01-06T01:31:24.008919Z"}}},{"cell_type":"code","source":"plt.figure(figsize=(14, 9))\n\nsns.regplot(x='Average Tackle Play Score per Game', y='Average Performance Index', data=merged_data)\n\nfor team in merged_data['Team'].unique():\n    team_data = merged_data[merged_data['Team'] == team]\n    plt.scatter(team_data['Average Tackle Play Score per Game'], team_data['Average Performance Index'], \n                color=team_data['Team Color'].iloc[0], label=team)\n\nfor _, row in merged_data.iterrows():\n    if row['Team'] in ['PHI', 'BUF', 'KC', 'MIN', 'NYG']:\n        plt.annotate(row['Team'], \n                     (row['Average Tackle Play Score per Game'], row['Average Performance Index']),\n                     textcoords=\"offset points\", \n                     xytext=(15, -5), \n                     ha='center')\n\nplt.xlabel('Average # of Tackle Plays per Game')\nplt.ylabel('Average Performance Index')\nplt.title('Average Performance Index vs Average Tackle Plays (with Linear Fit)')\nplt.ylim(0.2, 0.8)\nplt.legend(title='Teams', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:33.270777Z","iopub.execute_input":"2024-01-08T06:19:33.271791Z","iopub.status.idle":"2024-01-08T06:19:34.4596Z","shell.execute_reply.started":"2024-01-08T06:19:33.271758Z","shell.execute_reply":"2024-01-08T06:19:34.45855Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By utilizing the Performance Index, the scatter plot exhibits more compact data points. Let's see if we can gain better insights by examining other tackle-related metrics.","metadata":{}},{"cell_type":"code","source":"###############","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:34.461117Z","iopub.execute_input":"2024-01-08T06:19:34.462105Z","iopub.status.idle":"2024-01-08T06:19:34.466491Z","shell.execute_reply.started":"2024-01-08T06:19:34.462064Z","shell.execute_reply":"2024-01-08T06:19:34.46542Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing the Impact of Defensive Tackles on EPA\n\nOne metric to explore is the \"Expected Points Added\" (EPA) resulting from tackle plays by the defensive team. Let's take a quick look at the distribution of this key statistic.\n","metadata":{}},{"cell_type":"code","source":"# Clean plays_df to include only plays that are also in tackles_df\nplays_df_cleaned = plays_df[plays_df.set_index(['gameId', 'playId']).index.isin(tackles_df.set_index(['gameId', 'playId']).index)]\n\ntackles_enhanced = tackles_df.merge(plays_df_cleaned[['gameId', 'playId', 'quarter', 'down']], on=['gameId', 'playId'])\ntackles_enhanced = tackles_enhanced.merge(players_df[['nflId', 'position']], on='nflId', suffixes=('', '_defensivePlayer'))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:34.468089Z","iopub.execute_input":"2024-01-08T06:19:34.46874Z","iopub.status.idle":"2024-01-08T06:19:34.506707Z","shell.execute_reply.started":"2024-01-08T06:19:34.468702Z","shell.execute_reply":"2024-01-08T06:19:34.505547Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Plotting the distribution of Expected Points Added (EPA)\nplt.figure(figsize=(10, 6))\nsns.histplot(plays_df_cleaned['expectedPointsAdded'], bins=150, binrange=(-7.5, 7.5), kde=True)\nplt.title('Distribution of Expected Points Added (EPA)')\nplt.xlabel('Expected Points Added (EPA)')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:34.50801Z","iopub.execute_input":"2024-01-08T06:19:34.508322Z","iopub.status.idle":"2024-01-08T06:19:35.262738Z","shell.execute_reply.started":"2024-01-08T06:19:34.508294Z","shell.execute_reply":"2024-01-08T06:19:35.261728Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the number of plays for each pass result (C, R, NaN) and calculating average EPA for each\npass_result_counts = plays_df_cleaned['passResult'].value_counts(dropna=False)\naverage_epa_by_pass_result = plays_df_cleaned.groupby('passResult')['expectedPointsAdded'].mean()\n\n# Including the NaN (designed runs) in the calculation\naverage_epa_designed_runs = plays_df_cleaned[plays_df_cleaned['passResult'].isna()]['expectedPointsAdded'].mean()\n\nresult_df = pd.DataFrame({\n    'Number of Plays': pass_result_counts,\n    'Average EPA': average_epa_by_pass_result\n})\n\nresult_df.iloc[0, result_df.columns.get_loc('Average EPA')] = average_epa_designed_runs","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:35.263847Z","iopub.execute_input":"2024-01-08T06:19:35.264126Z","iopub.status.idle":"2024-01-08T06:19:35.279693Z","shell.execute_reply.started":"2024-01-08T06:19:35.264101Z","shell.execute_reply":"2024-01-08T06:19:35.278539Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we categorize plays by the \"passResult,\" three distinct types emerge: NaN (Run), Completed (C), and Scramble (R). The mean Expected Points Added (EPA) for each type of play shows notable differences. Below is a table summarizing the number of plays and their corresponding average EPA:\n\n| passResult     | Number of Plays | Average EPA |\n|----------------|-----------------|-------------|\n| NaN (Run)      | 6215            | -0.088942   |\n| C (Completed)  | 5354            | 0.623631    |\n| R (Scramble)   | 456             | 0.382322    |\n\nThis table offers an insightful look into how different play types contribute to the overall game dynamics in terms of EPA:\n\n1. **Runs (NaN):** With an average EPA of -0.088942, this indicates that tackles in defensive tactics against running plays are often effective, as a negative EPA is beneficial for the defense.\n\n2. **Completed Passes (C):** The high average EPA of 0.623631 for completed passes suggests that these plays are generally advantageous for the offense, leading to positive outcomes in terms of expected points.\n\n3. **Scrambles (R):** Scrambles have an average EPA of 0.382322, which is lower than completed passes but still positive, indicating these plays can be moderately effective for the offense.\n\nThe varying EPA values across different play types reflect the effectiveness of defensive strategies, particularly the success of tackles in limiting offensive gains, especially in running plays.\n","metadata":{}},{"cell_type":"code","source":"# Creating a deep copy of the plays_df_cleaned DataFrame\nplays_df_scaled = deepcopy(plays_df_cleaned)\n\n# Defining the conditions for each play type\nconditions = {\n    'C': plays_df_cleaned['passResult'] == 'C',\n    'R': plays_df_cleaned['passResult'] == 'R',\n    'NaN': plays_df_cleaned['passResult'].isna()\n}\n\n# Computing scaling parameters for each play type\nscaling_params = {}\nfor play_type, condition in conditions.items():\n    subset = plays_df_cleaned[condition]['expectedPointsAdded']\n    scaling_params[play_type] = {\n        'mean': subset.mean(),\n        'std': subset.std(),\n        'min': subset.min(),\n        'max': subset.max()\n    }\n\n# Applying the scaling parameters to the dataset\nfor play_type, params in scaling_params.items():\n    # Normalization\n    plays_df_scaled.loc[conditions[play_type], 'epa_normalized'] = (\n        plays_df_cleaned[conditions[play_type]]['expectedPointsAdded'] - params['min']\n    ) / (params['max'] - params['min'])\n    \n    # Standardization\n    plays_df_scaled.loc[conditions[play_type], 'epa_standardized'] = (\n        plays_df_cleaned[conditions[play_type]]['expectedPointsAdded'] - params['mean']\n    ) / params['std']","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-08T06:19:35.281016Z","iopub.execute_input":"2024-01-08T06:19:35.281517Z","iopub.status.idle":"2024-01-08T06:19:35.314393Z","shell.execute_reply.started":"2024-01-08T06:19:35.281488Z","shell.execute_reply":"2024-01-08T06:19:35.313653Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standardization and Normalization\n\nLet's calculate the normalized and standardized values of the Expected Points Added (EPA) for each play, scaled according to the play type (Complete Passes, Scrambles, Designed Runs).\n\n**Standardization** and **Normalization** are two common techniques in data preprocessing to transform data into a more suitable format for analysis.\n\n1. **Standardization**:\n   - This technique involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1. \n   - Formula: $$ \\text{Standardized Value} = \\frac{\\text{Value} - \\text{Mean}}{\\text{Standard Deviation}} $$\n\n2. **Normalization**:\n   - Normalization rescales the range of features to scale the range in [0, 1] or [-1, 1].\n   - Formula: $$ \\text{Normalized Value} = \\frac{\\text{Value} - \\text{Min Value}}{\\text{Max Value} - \\text{Min Value}} $$\n\nThe scaling was applied using vectorized operations for efficiency, with separate scaling parameters (mean, standard deviation, min, max) computed for each play type beforehand. This approach ensures that the EPA is adjusted in a contextually relevant manner, making the values more comparable across different play types.","metadata":{}},{"cell_type":"code","source":"# Creating a histogram for the distribution of normalized EPA values\nplt.figure(figsize=(12, 6))\nplt.hist(plays_df_scaled['epa_normalized'].dropna(), bins=50, color='purple', edgecolor='black')\nplt.title('Distribution of Normalized EPA')\nplt.xlabel('Normalized EPA')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:35.315485Z","iopub.execute_input":"2024-01-08T06:19:35.315814Z","iopub.status.idle":"2024-01-08T06:19:35.748319Z","shell.execute_reply.started":"2024-01-08T06:19:35.315784Z","shell.execute_reply":"2024-01-08T06:19:35.747271Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a histogram for the distribution of standardized EPA values for all plays\nplt.figure(figsize=(12, 6))\nplt.hist(plays_df_scaled['epa_standardized'].dropna(), bins=50, color='orange', edgecolor='black')\nplt.title('Distribution of Standardized EPA for All Plays')\nplt.xlabel('Standardized EPA')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:35.749852Z","iopub.execute_input":"2024-01-08T06:19:35.75026Z","iopub.status.idle":"2024-01-08T06:19:36.182226Z","shell.execute_reply.started":"2024-01-08T06:19:35.75022Z","shell.execute_reply":"2024-01-08T06:19:36.181223Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging the required columns from plays_df_scaled to tackles_df based on gameId and playId\ntackles_df = pd.merge(tackles_df, plays_df_scaled[['gameId', 'playId', 'epa_standardized', 'epa_normalized']], \n                      on=['gameId', 'playId'], how='left')\n\n# Calculating points for tackles and assists\n# Points are equal to 'epa_standardized' for a tackle, and half the value for an assist\ntackles_df['points_standardized'] = tackles_df['tackle'] * tackles_df['epa_standardized'] + \\\n                       (tackles_df['assist'] * tackles_df['epa_standardized']) / 2\n\ntackles_df['points_normalized'] = tackles_df['tackle'] * tackles_df['epa_normalized'] + \\\n                       (tackles_df['assist'] * tackles_df['epa_normalized']) / 2\n\n# Merge the two dataframes on 'gameId' and 'playId'\nmerged_df = pd.merge(tackles_df, plays_df_scaled[['gameId', 'playId', 'defensiveTeam']], on=['gameId', 'playId'], how='left')\n\n# Group by 'defensiveTeam' and 'gameId' and 'playId' to ensure each play is only counted once\ngrouped_df = merged_df.groupby(['defensiveTeam', 'gameId', 'playId']).agg({\n    'epa_standardized': 'mean',\n    'epa_normalized': 'mean'\n}).reset_index()\n\n# Sum the 'epa_standardized' and 'epa_normalized' by team\nteam_epa_df = grouped_df.groupby('defensiveTeam').agg({\n    'epa_standardized': 'sum',\n    'epa_normalized': 'sum'\n}).reset_index()\n\n# Calculate the number of games played by each team and their win rate\n# Create a dictionary to hold the win counts and game counts\nteam_games = {}\nfor index, row in games_df.iterrows():\n    home_team = row['homeTeamAbbr']\n    visitor_team = row['visitorTeamAbbr']\n    home_win = row['homeFinalScore'] > row['visitorFinalScore']\n\n    # Update counts for home team\n    if home_team not in team_games:\n        team_games[home_team] = {'games': 0, 'wins': 0}\n    team_games[home_team]['games'] += 1\n    if home_win:\n        team_games[home_team]['wins'] += 1\n\n    # Update counts for visitor team\n    if visitor_team not in team_games:\n        team_games[visitor_team] = {'games': 0, 'wins': 0}\n    team_games[visitor_team]['games'] += 1\n    if not home_win:\n        team_games[visitor_team]['wins'] += 1\n\nteam_games_df = pd.DataFrame.from_dict(team_games, orient='index').reset_index()\nteam_games_df.rename(columns={'index': 'defensiveTeam', 'games': 'games_played', 'wins': 'wins'}, inplace=True)\nteam_games_df['win_rate'] = team_games_df['wins'] / team_games_df['games_played']\n\nteam_epa_games_df = pd.merge(team_epa_df, team_games_df, on='defensiveTeam', how='left')","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:36.183443Z","iopub.execute_input":"2024-01-08T06:19:36.183782Z","iopub.status.idle":"2024-01-08T06:19:36.201772Z","shell.execute_reply.started":"2024-01-08T06:19:36.183753Z","shell.execute_reply":"2024-01-08T06:19:36.200772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Total EPA(Scaled)\n\nTo further understand the impact of defensive tackles, the sum of the scaled EPA generated by these plays for each team has been calculated. For a more comprehensive analysis, the average value per game will be considered. Below is a table showcasing this data for a selection of teams, along with their games played, wins, and win rate:\n\n| Defensive Team | Total EPA Standardized | Total EPA Normalized | Games Played | Wins | Win Rate  |\n|----------------|------------------------|----------------------|--------------|------|-----------|\n| ARI            | -8.039853              | 243.382918           | 9            | 3    | 0.333333  |\n| ATL            | 3.742326               | 260.263962           | 9            | 4    | 0.444444  |\n| BAL            | -5.033219              | 221.922163           | 9            | 6    | 0.666667  |\n| BUF            | -15.729452             | 202.712839           | 8            | 6    | 0.750000  |\n| CAR            | -15.826527             | 262.079248           | 9            | 2    | 0.222222  |\n\nThis table provides an initial overview of the correlation between the EPA contributed by defensive plays and overall team performance in terms of win rate.\n\n**Note**: For both **EPA Standardized** and **EPA Normalized**, the **smaller the values**, the **better** the team performs.\n","metadata":{}},{"cell_type":"code","source":"# Calculate the average scaled epa per game for both scaling methods\nteam_epa_games_df['avg_epa_standardized_per_game'] = team_epa_games_df['epa_standardized'] / team_epa_games_df['games_played']\nteam_epa_games_df['avg_epa_normalized_per_game'] = team_epa_games_df['epa_normalized'] / team_epa_games_df['games_played']\n\nmerged_data_subset = merged_data[['Team', 'Average Tackle Play Score per Game', 'Team Color', 'Average Performance Index']]\nnew_merged_df = team_epa_games_df.merge(merged_data_subset, left_on='defensiveTeam', right_on='Team')\n\nnew_merged_df.drop('Team', axis=1, inplace=True)\nnew_merged_df.to_csv('/kaggle/working/scaled_epa.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T07:07:25.267162Z","iopub.execute_input":"2024-01-08T07:07:25.268176Z","iopub.status.idle":"2024-01-08T07:07:25.281818Z","shell.execute_reply.started":"2024-01-08T07:07:25.268138Z","shell.execute_reply":"2024-01-08T07:07:25.280928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below is a table showing the average values per game for both standardized and normalized EPA for a selection of teams. This data will be used in subsequent plots to explore the relationship between these defensive performance metrics and team success, measured by win rate and performance index:\n\n| Defensive Team | Avg EPA Standardized/Game | Avg EPA Normalized/Game |\n|----------------|---------------------------|------------------------|\n| ARI            | -0.893317                 | 27.042546              |\n| ATL            | 0.415814                  | 28.918218              |\n| BAL            | -0.559247                 | 24.658018              |\n| BUF            | -1.966181                 | 25.339105              |\n| CAR            | -1.758503                 | 29.119916              |","metadata":{"execution":{"iopub.status.busy":"2024-01-08T04:21:31.570904Z","iopub.execute_input":"2024-01-08T04:21:31.571312Z","iopub.status.idle":"2024-01-08T04:21:31.586018Z","shell.execute_reply.started":"2024-01-08T04:21:31.571254Z","shell.execute_reply":"2024-01-08T04:21:31.584753Z"}}},{"cell_type":"code","source":"plt.figure(figsize=(14, 9))\n\n# Regression plot for standardized EPA vs Average Performance Index\nsns.regplot(x='avg_epa_standardized_per_game', y='Average Performance Index', data=new_merged_df, scatter=False)\n\n# Scatter plot for each team with standardized EPA\nfor index, row in new_merged_df.iterrows():\n    plt.scatter(row['avg_epa_standardized_per_game'], row['Average Performance Index'], \n                color=row['Team Color'], marker='o', label=row['defensiveTeam'])\n\n# Adding labels for specific teams if necessary\nhighlight_teams = ['PHI', 'BUF', 'KC', 'MIN', 'NYG']  # Example teams to highlight\nfor index, row in new_merged_df.iterrows():\n    if row['defensiveTeam'] in highlight_teams:\n        plt.annotate(row['defensiveTeam'], \n                     (row['avg_epa_standardized_per_game'], row['Average Performance Index']),\n                     textcoords=\"offset points\", \n                     xytext=(15, -5), \n                     ha='center')\n\n# Setting up plot titles and labels\nplt.title('Average Performance Index vs Average Standardized EPA per Game')\nplt.xlabel('Average Standardized EPA per Game')\nplt.ylabel('Average Performance Index')\nplt.grid(True)\nplt.legend(title='Teams', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:36.282722Z","iopub.execute_input":"2024-01-08T06:19:36.28311Z","iopub.status.idle":"2024-01-08T06:19:37.634933Z","shell.execute_reply.started":"2024-01-08T06:19:36.283075Z","shell.execute_reply":"2024-01-08T06:19:37.633876Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 9))\n\n# Regression plot for normalized EPA vs Average Performance Index\nsns.regplot(x='avg_epa_normalized_per_game', y='Average Performance Index', data=new_merged_df, scatter=False)\n\n# Scatter plot for each team with normalized EPA\nfor index, row in new_merged_df.iterrows():\n    plt.scatter(row['avg_epa_normalized_per_game'], row['Average Performance Index'], \n                color=row['Team Color'], marker='o', label=row['defensiveTeam'])\n\n# Adding labels for specific teams if necessary\nhighlight_teams = ['PHI', 'BUF', 'KC', 'MIN', 'NYG']  # Example teams to highlight\nfor index, row in new_merged_df.iterrows():\n    if row['defensiveTeam'] in highlight_teams:\n        plt.annotate(row['defensiveTeam'], \n                     (row['avg_epa_normalized_per_game'], row['Average Performance Index']),\n                     textcoords=\"offset points\", \n                     xytext=(15, -5), \n                     ha='center')\n\n# Setting up plot titles and labels\nplt.title('Average Performance Index vs Average Normalized EPA per Game')\nplt.xlabel('Average Normalized EPA per Game')\nplt.ylabel('Average Performance Index')\nplt.grid(True)\nplt.legend(title='Teams', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:37.636349Z","iopub.execute_input":"2024-01-08T06:19:37.637058Z","iopub.status.idle":"2024-01-08T06:19:38.941051Z","shell.execute_reply.started":"2024-01-08T06:19:37.637029Z","shell.execute_reply":"2024-01-08T06:19:38.940238Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 9))\n\nsns.regplot(x='avg_epa_standardized_per_game', y='win_rate', data=new_merged_df, scatter=False)\n\n# Scatter plot for each team\nfor index, row in new_merged_df.iterrows():\n    plt.scatter(row['avg_epa_standardized_per_game'], row['win_rate'], \n                color=row['Team Color'], marker='o', label=row['defensiveTeam'])\n\n# Adding labels for specific teams if necessary\nhighlight_teams = ['PHI', 'BUF', 'KC', 'MIN', 'NYG']  # Example teams to highlight\nfor index, row in new_merged_df.iterrows():\n    if row['defensiveTeam'] in highlight_teams:\n        plt.annotate(row['defensiveTeam'], \n                     (row['avg_epa_standardized_per_game'], row['win_rate']),\n                     textcoords=\"offset points\", \n                     xytext=(15, -5), \n                     ha='center')\n\n# Setting up plot titles and labels\nplt.title('Win Rate vs Average Standardized EPA per Game')\nplt.xlabel('Average Standardized EPA per Game')\nplt.ylabel('Win Rate')\nplt.grid(True)\nplt.legend(title='Teams', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:38.942316Z","iopub.execute_input":"2024-01-08T06:19:38.942972Z","iopub.status.idle":"2024-01-08T06:19:40.158026Z","shell.execute_reply.started":"2024-01-08T06:19:38.942931Z","shell.execute_reply":"2024-01-08T06:19:40.156909Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 9))\n\n# Regression plot for normalized EPA\nsns.regplot(x='avg_epa_normalized_per_game', y='win_rate', data=new_merged_df, scatter=False)\n\n# Scatter plot for each team with normalized EPA\nfor index, row in new_merged_df.iterrows():\n    plt.scatter(row['avg_epa_normalized_per_game'], row['win_rate'], \n                color=row['Team Color'], marker='o', label=row['defensiveTeam'])\n\n# Adding labels for specific teams if necessary\nhighlight_teams = ['PHI', 'BUF', 'KC', 'MIN', 'NYG']  # Example teams to highlight\nfor index, row in new_merged_df.iterrows():\n    if row['defensiveTeam'] in highlight_teams:\n        plt.annotate(row['defensiveTeam'], \n                     (row['avg_epa_normalized_per_game'], row['win_rate']),\n                     textcoords=\"offset points\", \n                     xytext=(15, -5), \n                     ha='center')\n\n# Setting up plot titles and labels\nplt.title('Win Rate vs Average Normalized EPA per Game')\nplt.xlabel('Average Normalized EPA per Game')\nplt.ylabel('Win Rate')\nplt.grid(True)\nplt.legend(title='Teams', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:40.159599Z","iopub.execute_input":"2024-01-08T06:19:40.160139Z","iopub.status.idle":"2024-01-08T06:19:41.429775Z","shell.execute_reply.started":"2024-01-08T06:19:40.160109Z","shell.execute_reply":"2024-01-08T06:19:41.428954Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_value_standardized_performance, r_squared_standardized_performance = calculate_regression_stats(new_merged_df['avg_epa_standardized_per_game'], new_merged_df['Average Performance Index'])\nr_value_normalized_performance, r_squared_normalized_performance = calculate_regression_stats(new_merged_df['avg_epa_normalized_per_game'], new_merged_df['Average Performance Index'])\nr_value_standardized_winrate, r_squared_standardized_winrate = calculate_regression_stats(new_merged_df['avg_epa_standardized_per_game'], new_merged_df['win_rate'])\nr_value_normalized_winrate, r_squared_normalized_winrate = calculate_regression_stats(new_merged_df['avg_epa_normalized_per_game'], new_merged_df['win_rate'])\n\n# Print each set of r_value and r_squared\n##print(\"Standardized EPA vs Average Performance Index: R Value =\", r_value_standardized_performance, \", R Squared =\", r_squared_standardized_performance)\n##print(\"Normalized EPA vs Average Performance Index: R Value =\", r_value_normalized_performance, \", R Squared =\", r_squared_normalized_performance)\n##print(\"Standardized EPA vs Win Rate: R Value =\", r_value_standardized_winrate, \", R Squared =\", r_squared_standardized_winrate)\n##print(\"Normalized EPA vs Win Rate: R Value =\", r_value_normalized_winrate, \", R Squared =\", r_squared_normalized_winrate)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:41.431022Z","iopub.execute_input":"2024-01-08T06:19:41.431732Z","iopub.status.idle":"2024-01-08T06:19:41.440729Z","shell.execute_reply.started":"2024-01-08T06:19:41.4317Z","shell.execute_reply":"2024-01-08T06:19:41.439792Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n## Summary of Correlations\n\nSome intriguing correlations between EPA metrics and team performance indicators. Below is a summarized table of these correlations:\n\n| Correlation Type                                   | R Value        | R Squared     |\n|----------------------------------------------------|----------------|---------------|\n| Standardized EPA vs Average Performance Index      | -0.203         | 0.0412        |\n| Normalized EPA vs Average Performance Index        | -0.324         | 0.105         |\n| Standardized EPA vs Win Rate                       | -0.249         | 0.0618        |\n| Normalized EPA vs Win Rate                         | -0.237         | 0.0562        |\n\nThe relationship between Normalized EPA and the Average Performance Index shows a moderate correlation. This is noteworthy, especially considering that the analysis is based solely on tackle-related statistics. The corresponding scatter plot reveals that even with slight variations in Normalized EPA, there's a noticeable impact on team performance. The decline in team performance as EPA increases suggests a potential area of focus for NFL teams.\n\nIn addition to team performance, the scaled EPA metric can be used to assess individual player performance, providing insights into the effectiveness of each player's contributions on the field.\n\nThis information can be particularly useful for teams to monitor and assess their tackling efficiency. Since the points are normalized, they provide a more equitable comparison across different tackle types.\n\nAdditionally, there's potential for a machine learning approach to further refine the scaling of EPA generated by tackles. While this aspect wasn't completed in this analysis, it represents a promising direction for future exploration to enhance our understanding of tackle efficiency and its impact on game outcomes.\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n**End of Main Report**\n\nThank you for your attention to this analysis. For additional insights and visualizations, please refer to the appendices.\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Acknowledgements\n\nI would like to extend my sincere thanks to the organizers of the NFL Big Data Bowl for creating this fantastic opportunity for data enthusiasts and football fans alike. The chance to dive into such a rich dataset and explore the intricacies of NFL gameplay has been both challenging and immensely rewarding.\n\nWhile time constraints limited the extent of my analysis, the experience was thoroughly enjoyable and enlightening. I am grateful for having had the opportunity to contribute and learn through this process.\n\nLooking forward to participating in future events, I am excited to continue this journey of data exploration and sports analytics. A big thank you once again to everyone involved in making this event possible and so engaging.\n","metadata":{}},{"cell_type":"markdown","source":"# Appendix\n\nIn this appendix, I've included a series of plots and animations that complement the main analysis of the report. These visual elements are designed to provide further insights into the data and to offer an engaging way to explore the dynamics of NFL games.\n\n### Visualizations\n\n- **Individual Defensive Player Tackle Statistics:** This section presents tables and plots showcasing the scaled EPA (Expected Points Added) for individual defensive players. These visualizations in the appendix offer a supplementary view, focusing on the contribution of each player to the team’s defensive performance.\n- **Heat Maps:** These offer a visual representation of the density of data, highlighting areas of high activity or interest in the dataset.","metadata":{"execution":{"iopub.status.busy":"2024-01-07T22:44:29.732884Z","iopub.execute_input":"2024-01-07T22:44:29.733369Z","iopub.status.idle":"2024-01-07T22:44:29.746687Z","shell.execute_reply.started":"2024-01-07T22:44:29.733307Z","shell.execute_reply":"2024-01-07T22:44:29.745086Z"}}},{"cell_type":"code","source":"# Calculate the total number of attempts (tackle, assist, or missed tackle) for each player\ntackles_df['total_attempts'] = tackles_df['tackle'] + tackles_df['assist'] + tackles_df['pff_missedTackle']\n\n# Summing the 'points_standardized' and 'points_normalized' for each player\n# Also calculating the average points per attempt\nplayer_points_summary = tackles_df.groupby('nflId').agg(\n    total_points_standardized=pd.NamedAgg(column='points_standardized', aggfunc='sum'),\n    total_points_normalized=pd.NamedAgg(column='points_normalized', aggfunc='sum'),\n    total_attempts=pd.NamedAgg(column='total_attempts', aggfunc='sum')\n)\n\n# Calculate average points per attempt\nplayer_points_summary['average_points_standardized'] = player_points_summary['total_points_standardized'] / player_points_summary['total_attempts']\nplayer_points_summary['average_points_normalized'] = player_points_summary['total_points_normalized'] / player_points_summary['total_attempts']\n\nplayer_points_summary.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:41.442153Z","iopub.execute_input":"2024-01-08T06:19:41.442812Z","iopub.status.idle":"2024-01-08T06:19:41.464482Z","shell.execute_reply.started":"2024-01-08T06:19:41.442781Z","shell.execute_reply":"2024-01-08T06:19:41.463545Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge player_points_summary with players_df to add player names\n# We use nflId as the key for merging\nplayer_points_summary = player_points_summary.merge(players_df[['nflId', 'displayName']], on='nflId', how='left')\n\nplayer_team_info = plays_df_cleaned[['gameId', 'playId', 'defensiveTeam']].drop_duplicates()\ntackles_with_team = tackles_df.merge(player_team_info, on=['gameId', 'playId'], how='left')\n\nplayer_points_summary_with_team = player_points_summary.merge(\n    tackles_with_team[['nflId', 'defensiveTeam']].drop_duplicates(), on='nflId', how='left')\n\nplayer_points_summary_with_team = player_points_summary_with_team.merge(players_df[['nflId', 'position']], on='nflId', how='left')\n\nplayer_points_summary_with_team.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:41.4657Z","iopub.execute_input":"2024-01-08T06:19:41.465982Z","iopub.status.idle":"2024-01-08T06:19:41.505494Z","shell.execute_reply.started":"2024-01-08T06:19:41.465957Z","shell.execute_reply":"2024-01-08T06:19:41.50476Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting a histogram for 'total_attempts'\nplt.figure(figsize=(10, 6))\nplt.hist(player_points_summary_with_team['total_attempts'], bins=100, range=(0, 100), color='blue', alpha=0.7)\nplt.title('Histogram of Total Attempts by Players')\nplt.xlabel('Total Attempts')\nplt.ylabel('Number of Players')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:41.506501Z","iopub.execute_input":"2024-01-08T06:19:41.507276Z","iopub.status.idle":"2024-01-08T06:19:41.987624Z","shell.execute_reply.started":"2024-01-08T06:19:41.507244Z","shell.execute_reply":"2024-01-08T06:19:41.986505Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting histograms for 'average_points_standardized' and 'average_points_normalized'\n\nplt.figure(figsize=(15, 6))\n\n# Histogram for 'average_points_standardized'\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\nplt.hist(player_points_summary_with_team['average_points_standardized'], bins=30, color='orange', alpha=0.7)\nplt.title('Histogram of Average Points (Standardized) per Attempt')\nplt.xlabel('Average Points (Standardized) per Attempt')\nplt.ylabel('Number of Players')\nplt.grid(True)\n\n# Histogram for 'average_points_normalized'\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\nplt.hist(player_points_summary_with_team['average_points_normalized'], bins=30, color='purple', alpha=0.7)\nplt.title('Histogram of Average Points (Normalized) per Attempt')\nplt.xlabel('Average Points (Normalized) per Attempt')\nplt.ylabel('Number of Players')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:41.991325Z","iopub.execute_input":"2024-01-08T06:19:41.992003Z","iopub.status.idle":"2024-01-08T06:19:42.802955Z","shell.execute_reply.started":"2024-01-08T06:19:41.99197Z","shell.execute_reply":"2024-01-08T06:19:42.80193Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_points_summary_with_team.sort_values(by='total_points_standardized', ascending=True).head(10)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:42.804512Z","iopub.execute_input":"2024-01-08T06:19:42.804871Z","iopub.status.idle":"2024-01-08T06:19:42.821773Z","shell.execute_reply.started":"2024-01-08T06:19:42.804841Z","shell.execute_reply":"2024-01-08T06:19:42.820645Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_points_summary_with_team.sort_values(by='total_points_normalized', ascending=True).head(10)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:42.823436Z","iopub.execute_input":"2024-01-08T06:19:42.823887Z","iopub.status.idle":"2024-01-08T06:19:42.843201Z","shell.execute_reply.started":"2024-01-08T06:19:42.823849Z","shell.execute_reply":"2024-01-08T06:19:42.84219Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correcting the data preparation for heatmaps\n# For heatmap 1 (by quarters), we sum up each type of tackle event\nheatmap1_data = tackles_enhanced.groupby('quarter')[['tackle', 'assist', 'forcedFumble', 'pff_missedTackle']].sum()\n\n# For heatmap 2 (by downs), we sum up each type of tackle event\nheatmap2_data = tackles_enhanced.groupby('down')[['tackle', 'assist', 'forcedFumble', 'pff_missedTackle']].sum()\n\n# Plotting the first heatmap (tackle events by quarters)\nplt.figure(figsize=(10, 6))\nsns.heatmap(heatmap1_data, annot=True, fmt=\"d\", cmap='viridis')\nplt.title(\"Tackle Events by Quarters\")\nplt.ylabel(\"Quarter\")\nplt.xlabel(\"Tackle Type\")\nplt.show()\n\n# Plotting the second heatmap (tackle events by downs)\nplt.figure(figsize=(10, 6))\nsns.heatmap(heatmap2_data, annot=True, fmt=\"d\", cmap='viridis')\nplt.title(\"Tackle Events by Downs\")\nplt.ylabel(\"Down\")\nplt.xlabel(\"Tackle Type\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:42.844529Z","iopub.execute_input":"2024-01-08T06:19:42.844864Z","iopub.status.idle":"2024-01-08T06:19:43.768763Z","shell.execute_reply.started":"2024-01-08T06:19:42.844835Z","shell.execute_reply":"2024-01-08T06:19:43.767745Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tackle Events by Quarters\n\n*Observations:*\n- Increased tackle events in later quarters, particularly the 4th quarter.\n- Missed tackles are somewhat evenly distributed across quarters.\n- Assists and forced fumbles are less frequent, with even distribution.\n\n### Tackle Events by Downs\n\n*Observations:*\n- Majority of tackles occur on the first and second downs.\n- Third down shows fewer tackle events.\n- Fourth down has the least number of tackle events.","metadata":{}},{"cell_type":"markdown","source":"### Tackle to Missed Tackle Ratios\n\n**Ratios by Quarter:**\n- Quarter 1: 5.52\n- Quarter 2: 4.53\n- Quarter 3: 4.38\n- Quarter 4: 4.68\n- Overtime (Quarter 5): 5.73\n\n**Ratios by Down:**\n- Down 1: 4.59\n- Down 2: 4.80\n- Down 3: 4.82\n- Down 4: 13.90\n\n*Observations:*\n- Consistent ratios across quarters with a slight increase in the 1st quarter and overtime.\n- Notable outlier in the fourth down, indicating higher tackle success.","metadata":{}},{"cell_type":"code","source":"# Creating a new DataFrame for the combined heatmap with quarter and down combinations\ntackles_combined = tackles_enhanced.copy()\n# Modifying the quarter_down category to follow the format \"Q#-D#\"\ntackles_combined['quarter_down'] = 'Q' + tackles_combined['quarter'].astype(str) + '-D' + tackles_combined['down'].astype(str)\n\n# Regrouping by the modified quarter_down category\nheatmap_combined_data = tackles_combined.groupby('quarter_down')[['tackle', 'assist', 'forcedFumble', 'pff_missedTackle']].sum()\n\n# Creating the heatmap with square cells\nplt.figure(figsize=(20, 8))\nsns.heatmap(heatmap_combined_data.T, annot=True, fmt=\"d\", cmap='plasma', square=True)\nplt.title(\"Tackle Events by Quarter-Down Combination\")\nplt.ylabel(\"Tackle Type\")\nplt.xlabel(\"Quarter-Down\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:43.770193Z","iopub.execute_input":"2024-01-08T06:19:43.770628Z","iopub.status.idle":"2024-01-08T06:19:44.554462Z","shell.execute_reply.started":"2024-01-08T06:19:43.770569Z","shell.execute_reply":"2024-01-08T06:19:44.55372Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tackle Events by Quarter-Down Combination\n\n*Observations:*\n- **Tackles:** More frequent in early downs, with an increase in the 4th quarter.\n- **Missed Tackles:** Evenly distributed, suggesting consistent performance.\n- **Forced Fumbles:** Slight increase in the 4th quarter, indicating aggressive play.\n- **Assists:** Similar pattern to solo tackles, consistent across game situations.","metadata":{}},{"cell_type":"code","source":"# Merging tackles_df with players_df to add the position of the defensive players\ntackles_df_with_position = tackles_df.merge(players_df[['nflId', 'position']], on='nflId', how='left')\n\n# Grouping by position and summing up each type of tackle event\nheatmap_position_data = tackles_df_with_position.groupby('position')[['tackle', 'assist', 'forcedFumble', 'pff_missedTackle']].sum()\n\n# Creating the heatmap\nplt.figure(figsize=(15, 8))\nsns.heatmap(heatmap_position_data.T, annot=True, fmt=\"d\", cmap='viridis', square=True)\nplt.title(\"Tackle Events by Defensive Player Position\")\nplt.ylabel(\"Tackle Type\")\nplt.xlabel(\"Position\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:19:44.559741Z","iopub.execute_input":"2024-01-08T06:19:44.560633Z","iopub.status.idle":"2024-01-08T06:19:45.133572Z","shell.execute_reply.started":"2024-01-08T06:19:44.560593Z","shell.execute_reply":"2024-01-08T06:19:45.132799Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average Heights and Weights of Offensive and Defensive Players\r\n\r\n- **Offensive Players:**\r\n  - **Average Height:** Approximately 74.64 inches (about 6 feet 2.64 inches)\r\n  - **Average Weight:** Approximately 250.18 pounds\r\n\r\n- **Defensive Players:**\r\n  - **Average Height:** Approximately 74.08 inches (about 6 feet 2.08 inches)\r\n  - **Average Weight:** Approximately 252.58 pounds\r\n\r\n*Note:*\r\n- These averages provide a general understanding of the physical stature of players in offensive and defensive roles, highlighting that both groups are quite similar in height, with defensive players being slightly heavier on average.\r\n","metadata":{}},{"cell_type":"markdown","source":"## License\n\nThis Notebook is released under the [Apache 2.0 open source license](https://opensource.org/licenses/Apache-2.0).\n","metadata":{}}]}